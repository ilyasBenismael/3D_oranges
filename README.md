# On-Tree Citrus Fruit Sizing via 3D Reconstruction

Accurately estimating fruit size is essential in precision agriculture for **yield prediction and quality control**.  
Traditional sensor-based or manual methods are either **expensive** or **impractical at scale**, while RGB-based approaches offer a **low-cost and easily deployable alternative** using just consumer smartphones.  

This repository presents a **complete RGB-based 3D reconstruction pipeline** designed for **on-tree fruit sizing**.  
Each component of the pipeline ‚Äî from segmentation to metric scaling and geometric fitting ‚Äî was carefully selected and experimentally validated to identify the most **robust and accurate 3D reconstruction methods** under orchard conditions.


---

## Pipeline Overview

<p align="center">
  <img src="imgs/pipeline.jpg" width="70%" alt="Pipeline Overview">
</p>

The pipeline follows a structured, end-to-end process:

1. **Video Capture** ‚Äì short RGB video of the tree containing fruits and a known-size reference object  
2. **Frame Extraction** ‚Äì sharp frames are selected from the video  
3. **2D Segmentation** ‚Äì fruits detected using *GroundingDINO* and segmented with *Segment Anything (SAM)*  
4. **3D Reconstruction** ‚Äì scene reconstructed via *SfM*, *PatchMatch-MVS*, or neural methods (*3DGS*, *SuGaR*)  
5. **Metric Scaling** ‚Äì reconstruction scaled to real-world units using the reference object  
6. **Clustering and Fitting** ‚Äì fruits isolated with *HDBSCAN*, then sphere fitting used to estimate diameters  
7. **Final Output** ‚Äì fruit diameters in millimeters with visual and quantitative evaluation

---


### üéûÔ∏è Frame Extraction

**Goal:**  
Select the sharpest frames dynamically from the input video to ensure high-quality reconstruction, regardless of camera model, resolution, or frame rate.

**Input:**  
Video of a scanned tree (`.mp4`)

**Output:**  
Group of sharp images (`.jpg`) extracted from the video

**Mechanism (in short):**  
- The video‚Äôs resolution and FPS are read automatically.  
- Approximately one frame is sampled every five (adaptive to different FPS values).  
- For each group of frames, sharpness is measured using the **Laplacian variance** method.  
- Only the sharpest frames above a dynamic blur threshold are kept.  
- The process adapts to image resolution ‚Äî higher thresholds for HD images, lower for smaller ones.  

This ensures that only **crisp, well-focused frames** are selected as reliable input for the next pipeline stages.



